{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5fcb970151a044e7936536b3d3efe6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c39df92855934eb09466a5b186d0e70b",
              "IPY_MODEL_7e39694ee9c745ca8f41570757142946",
              "IPY_MODEL_5ef2ec5c571f4ae5a43f2ba89b05a4bd"
            ],
            "layout": "IPY_MODEL_da44fddebac2445eb73eea0b20369993"
          }
        },
        "c39df92855934eb09466a5b186d0e70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cceb24c38af44498e737dff962d78c8",
            "placeholder": "​",
            "style": "IPY_MODEL_ac5175d1c8bf41d0857ebc8882038887",
            "value": "Downloading builder script: 100%"
          }
        },
        "7e39694ee9c745ca8f41570757142946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6649b08da114b82b9364b23de0c14de",
            "max": 4485,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8cda7fbf0eb4db68bbd909760ef53cd",
            "value": 4485
          }
        },
        "5ef2ec5c571f4ae5a43f2ba89b05a4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe6f23d05aac4b8a80bd6de08f36b9e2",
            "placeholder": "​",
            "style": "IPY_MODEL_56ca0d863d1a4e918f557c622a00721a",
            "value": " 4.49k/4.49k [00:00&lt;00:00, 316kB/s]"
          }
        },
        "da44fddebac2445eb73eea0b20369993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cceb24c38af44498e737dff962d78c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac5175d1c8bf41d0857ebc8882038887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6649b08da114b82b9364b23de0c14de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8cda7fbf0eb4db68bbd909760ef53cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe6f23d05aac4b8a80bd6de08f36b9e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ca0d863d1a4e918f557c622a00721a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets fsspec huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbKcd93HWP6N",
        "outputId": "94c58f3d-50c9-4879-91c2-d825c34f8b3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49gj3TaD4J8f",
        "outputId": "5d768570-7f41-4160-9556-995f9572fb99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"Teklia/IAM-line\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# Check dataset keys\n",
        "print(ds)\n",
        "\n",
        "# Print the first example from the train split\n",
        "print(ds['train'][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVHZOMVYV4kZ",
        "outputId": "6df54962-42ed-48b5-b6b3-9ea544443fd4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['image', 'text'],\n",
            "        num_rows: 6482\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['image', 'text'],\n",
            "        num_rows: 976\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['image', 'text'],\n",
            "        num_rows: 2915\n",
            "    })\n",
            "})\n",
            "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=L size=2467x128 at 0x7C66F913E150>, 'text': 'put down a resolution on the subject'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrOCRProcessor\n",
        "\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j_svWpwimQi",
        "outputId": "676433c3-c75b-4325-a965-41aa2469f080"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(example):\n",
        "    # Convert image to RGB\n",
        "    image = example[\"image\"].convert(\"RGB\")\n",
        "\n",
        "    # Processor automatically resizes & normalizes\n",
        "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values[0]\n",
        "\n",
        "    # Tokenize labels\n",
        "    labels = processor.tokenizer(\n",
        "        example[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    ).input_ids\n",
        "\n",
        "    # Replace padding token IDs with -100 (ignored in loss)\n",
        "    labels = [label if label != processor.tokenizer.pad_token_id else -100 for label in labels]\n",
        "\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n"
      ],
      "metadata": {
        "id": "_hJJzTocj8vL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.map(preprocess, remove_columns=ds[\"train\"].column_names)\n"
      ],
      "metadata": {
        "id": "7P0arYq9klo6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class IAMDataset(Dataset):\n",
        "    def __init__(self, hf_dataset):\n",
        "        self.dataset = hf_dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        return {\n",
        "            \"pixel_values\": item[\"pixel_values\"],\n",
        "            \"labels\": item[\"labels\"]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "hdkwNEjIls2o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = IAMDataset(ds[\"train\"])\n",
        "val_dataset = IAMDataset(ds[\"validation\"])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=4)\n"
      ],
      "metadata": {
        "id": "9mEG2g8Rn74T"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel\n",
        "\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
        "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "model.config.vocab_size = model.decoder.config.vocab_size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ-EWxDZoQZQ",
        "outputId": "a1fdc2de-1ce0-44f5-8c9a-b260baaba93d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 384,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"pooler_act\": \"tanh\",\n",
            "  \"pooler_output_size\": 768,\n",
            "  \"qkv_bias\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.3\"\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"cross_attention_hidden_size\": 768,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layernorm_embedding\": true,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"trocr\",\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": false,\n",
            "  \"use_learned_position_embeddings\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "scaler = GradScaler()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Qb_cl2oyCt",
        "outputId": "2f0bbba8-a76e-42ab-de15-250afdfacfec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-91324fc5889e>:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "AUT_cwxizaPW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    pixel_values = torch.stack([x[\"pixel_values\"] for x in batch])\n",
        "    labels = [torch.tensor(x[\"labels\"]) for x in batch]\n",
        "\n",
        "    # Pad labels manually (important for text)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=processor.tokenizer.pad_token_id)\n",
        "\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n"
      ],
      "metadata": {
        "id": "CLLpC5T60G7b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from tqdm import tqdm\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "# # Define the collate_fn before creating DataLoaders\n",
        "# def collate_fn(batch):\n",
        "#     pixel_values = torch.stack([x[\"pixel_values\"] for x in batch])\n",
        "#     labels = [torch.tensor(x[\"labels\"]) for x in batch]\n",
        "\n",
        "#     # Pad labels manually (important for text)\n",
        "#     labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=processor.tokenizer.pad_token_id)\n",
        "\n",
        "#     return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "# # Update DataLoader creation to include collate_fn\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=4, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# for epoch in range(10):  # You can later add early stopping if needed\n",
        "#     model.train()\n",
        "#     loop = tqdm(train_dataloader, leave=True)\n",
        "#     total_loss = 0\n",
        "\n",
        "#     for batch in loop:\n",
        "#         # After applying collate_fn, batch[\"pixel_values\"] will be a tensor\n",
        "#         pixel_values = batch[\"pixel_values\"].to(device)\n",
        "#         # After applying collate_fn, batch[\"labels\"] will be a tensor\n",
        "#         labels = batch[\"labels\"].to(device) # labels is already a tensor from collate_fn\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         with autocast():\n",
        "#             outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "#             loss = outputs.loss\n",
        "\n",
        "#         scaler.scale(loss).backward()\n",
        "#         scaler.step(optimizer)\n",
        "#         scaler.update()\n",
        "\n",
        "#         loop.set_description(f\"Epoch {epoch}\")\n",
        "#         loop.set_postfix(loss=loss.item())\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#     avg_loss = total_loss / len(train_dataloader)\n",
        "#     print(f\"Epoch {epoch} Avg Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "mvpTN2HJsqSe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from tqdm import tqdm\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "# # Define the collate_fn before creating DataLoaders\n",
        "# def collate_fn(batch):\n",
        "#     # Ensure each item's pixel_values is treated as a tensor before stacking\n",
        "#     pixel_values = torch.stack([torch.as_tensor(x[\"pixel_values\"]) for x in batch])\n",
        "#     labels = [torch.tensor(x[\"labels\"]) for x in batch]\n",
        "\n",
        "#     # Pad labels manually (important for text)\n",
        "#     # Ensure padding_value is a tensor\n",
        "#     labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=processor.tokenizer.pad_token_id)\n",
        "\n",
        "\n",
        "#     return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "# # Update DataLoader creation to include collate_fn\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=4, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# for epoch in range(1):  # You can later add early stopping if needed\n",
        "#     model.train()\n",
        "#     loop = tqdm(train_dataloader, leave=True)\n",
        "#     total_loss = 0\n",
        "\n",
        "#     for batch in loop:\n",
        "#         # After applying collate_fn, batch[\"pixel_values\"] will be a tensor\n",
        "#         pixel_values = batch[\"pixel_values\"].to(device)\n",
        "#         # After applying collate_fn, batch[\"labels\"] will be a tensor\n",
        "#         labels = batch[\"labels\"].to(device) # labels is already a tensor from collate_fn\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         with autocast():\n",
        "#             outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "#             loss = outputs.loss\n",
        "\n",
        "#         scaler.scale(loss).backward()\n",
        "#         scaler.step(optimizer)\n",
        "#         scaler.update()\n",
        "\n",
        "#         loop.set_description(f\"Epoch {epoch}\")\n",
        "#         loop.set_postfix(loss=loss.item())\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#     avg_loss = total_loss / len(train_dataloader)\n",
        "#     print(f\"Epoch {epoch} Avg Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "31dS2DPixIh8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from tqdm import tqdm\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "# # Define the collate_fn before creating DataLoaders\n",
        "# def collate_fn(batch):\n",
        "#     # Ensure each item's pixel_values is treated as a tensor before stacking\n",
        "#     pixel_values = torch.stack([torch.as_tensor(x[\"pixel_values\"]) for x in batch])\n",
        "#     labels = [torch.tensor(x[\"labels\"]) for x in batch]\n",
        "\n",
        "#     # Pad labels manually (important for text)\n",
        "#     # Ensure padding_value is a tensor\n",
        "#     labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=processor.tokenizer.pad_token_id)\n",
        "\n",
        "#     return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "# # Update DataLoader creation to include collate_fn, num_workers, and pin_memory\n",
        "# # Start with a small number of workers (e.g., 2 or 4) and increase it if it helps\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=4, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "# for epoch in range(1):  # You can later add early stopping if needed\n",
        "#     model.train()\n",
        "#     loop = tqdm(train_dataloader, leave=True)\n",
        "#     total_loss = 0\n",
        "\n",
        "#     for batch in loop:\n",
        "#         # After applying collate_fn, batch[\"pixel_values\"] will be a tensor\n",
        "#         pixel_values = batch[\"pixel_values\"].to(device)\n",
        "#         # After applying collate_fn, batch[\"labels\"] will be a tensor\n",
        "#         labels = batch[\"labels\"].to(device) # labels is already a tensor from collate_fn\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         with autocast():\n",
        "#             outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "#             loss = outputs.loss\n",
        "\n",
        "#         scaler.scale(loss).backward()\n",
        "#         scaler.step(optimizer)\n",
        "#         scaler.update()\n",
        "\n",
        "#         loop.set_description(f\"Epoch {epoch}\")\n",
        "#         loop.set_postfix(loss=loss.item())\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#     avg_loss = total_loss / len(train_dataloader)\n",
        "#     print(f\"Epoch {epoch} Avg Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "EkiIqWt5x5Ib"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define collate function\n",
        "def collate_fn(batch):\n",
        "    pixel_values = torch.stack([torch.as_tensor(x[\"pixel_values\"]) for x in batch])\n",
        "    labels = [torch.tensor(x[\"labels\"]) for x in batch]\n",
        "\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(\n",
        "        labels, batch_first=True, padding_value=processor.tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "# Subsets for debugging/speed\n",
        "train_dataset_subset = Subset(train_dataset, range(10))\n",
        "val_dataset_subset = Subset(val_dataset, range(3))  # Limit validation to 3 samples\n",
        "\n",
        "# DataLoaders\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset_subset, batch_size=4, shuffle=True,\n",
        "    collate_fn=collate_fn, num_workers=0, pin_memory=True\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset_subset, batch_size=1, shuffle=False,\n",
        "    collate_fn=collate_fn, num_workers=0, pin_memory=True\n",
        ")\n",
        "\n",
        "# Training loop (1 epoch for quick test)\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    loop = tqdm(train_dataloader, leave=True)\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in loop:\n",
        "        pixel_values = batch[\"pixel_values\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        loop.set_description(f\"Epoch {epoch}\")\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch} Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "for batch in tqdm(val_dataloader):\n",
        "    pixel_values = batch[\"pixel_values\"].to(device)\n",
        "    labels = batch[\"labels\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(pixel_values.to(device))\n",
        "\n",
        "    # Decode predictions\n",
        "    pred_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Clean up labels: remove -100 and ensure they are valid token IDs\n",
        "    cleaned_labels = []\n",
        "    for label in labels:\n",
        "        label = label[label != -100]  # Remove ignored indices\n",
        "        label = label[label < processor.tokenizer.vocab_size]  # Avoid large integers\n",
        "        cleaned_labels.append(label)\n",
        "\n",
        "    label_texts = processor.batch_decode(cleaned_labels, skip_special_tokens=True)\n",
        "\n",
        "    predictions.extend(pred_texts)\n",
        "    references.extend(label_texts)\n",
        "\n",
        "# Print results\n",
        "for i, (pred, ref) in enumerate(zip(predictions, references)):\n",
        "    print(f\"\\nSample {i+1}:\")\n",
        "    print(f\"Prediction: {pred}\")\n",
        "    print(f\"Reference : {ref}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RANvE7AOjx5",
        "outputId": "c704f9da-4dca-4687-db76-2d21982b1179"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]<ipython-input-17-83f4d3ec765b>:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 0: 100%|██████████| 3/3 [02:17<00:00, 45.84s/it, loss=5.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Avg Loss: 6.5096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:57<00:00, 19.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample 1:\n",
            "Prediction: A K is a Mr Gakell M for Mr Gakell M for Mr Gakell M for Mr\n",
            "Reference : It was a splendid interpretation of the\n",
            "\n",
            "Sample 2:\n",
            "Prediction: sympathetic to Mr Gakekekekekekekekekekekekekeke\n",
            "Reference : sympathetic C O . Paul Daneman gave another\n",
            "\n",
            "Sample 3:\n",
            "Prediction: past of Mr Ga to Mr Gakell P to Mr Gakell Mr Gakell Mr Gakell from\n",
            "Reference : part . The rest of the cast were well chosen ,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "\n",
        "import evaluate\n",
        "\n",
        "# Load the CER metric\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "\n",
        "# Compute CER\n",
        "cer = cer_metric.compute(predictions=predictions, references=references)\n",
        "print(f\"Character Error Rate (CER): {cer:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6ohojlDSzlF",
        "outputId": "b08e0f98-add1-49d1-f184-738cffa9d701"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Character Error Rate (CER): 0.9766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "\n",
        "import evaluate\n",
        "\n",
        "# Load the WER metric\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "# Compute WER\n",
        "wer = wer_metric.compute(predictions=predictions, references=references)\n",
        "print(f\"Word Error Rate (WER): {wer:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666,
          "referenced_widgets": [
            "5fcb970151a044e7936536b3d3efe6ce",
            "c39df92855934eb09466a5b186d0e70b",
            "7e39694ee9c745ca8f41570757142946",
            "5ef2ec5c571f4ae5a43f2ba89b05a4bd",
            "da44fddebac2445eb73eea0b20369993",
            "3cceb24c38af44498e737dff962d78c8",
            "ac5175d1c8bf41d0857ebc8882038887",
            "e6649b08da114b82b9364b23de0c14de",
            "e8cda7fbf0eb4db68bbd909760ef53cd",
            "fe6f23d05aac4b8a80bd6de08f36b9e2",
            "56ca0d863d1a4e918f557c622a00721a"
          ]
        },
        "id": "hbl2eF2sTf5g",
        "outputId": "322eb95f-f9fb-40e9-ac05-47323f5bead1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fcb970151a044e7936536b3d3efe6ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Error Rate (WER): 1.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1iBy-k__UGry"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
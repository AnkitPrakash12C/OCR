Handwriting Recognition with OCR using Transformer Models involved designing and implementing a complete OCR system utilizing the IAM Handwriting Dataset and a Vision-Encoder-Decoder Transformer Model (ViT-GPT2) from Hugging Face. The model was fine-tuned on handwritten text line images to accurately convert them into digital transcriptions, demonstrating the ability to customize and adapt large language models for specific NLP tasks. The project included comprehensive image preprocessing techniques such as resizing, padding, and normalization, followed by decoding and inference to produce clean text outputs. It leveraged the Hugging Face ecosystem for efficient dataset handling, model configuration, and training workflows. Additionally, the system was designed with scalability in mind, supporting evaluation metrics like Word Error Rate (WER) and Character Error Rate (CER), and structured for potential real-world deployment in document digitization and handwriting recognition applications.
